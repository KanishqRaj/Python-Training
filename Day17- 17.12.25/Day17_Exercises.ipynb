{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3E9MjtVjdLC"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder \\\n",
        ".appName(\"Retail Sales Analysis\") \\\n",
        ".getOrCreate()\n",
        "\n",
        "sales_data = [\n",
        "(\"T001\",\"North\",\"Delhi\",\"Store-01\",\"Laptop\",\"2024-01-01\",75000),\n",
        "(\"T002\",\"North\",\"Delhi\",\"Store-01\",\"Mobile\",\"2024-01-02\",32000),\n",
        "(\"T003\",\"North\",\"Chandigarh\",\"Store-02\",\"Tablet\",\"2024-01-03\",26000),\n",
        "(\"T004\",\"South\",\"Bangalore\",\"Store-03\",\"Laptop\",\"2024-01-01\",78000),\n",
        "(\"T005\",\"South\",\"Chennai\",\"Store-04\",\"Mobile\",\"2024-01-02\",30000),\n",
        "(\"T006\",\"South\",\"Bangalore\",\"Store-03\",\"Tablet\",\"2024-01-03\",24000),\n",
        "(\"T007\",\"East\",\"Kolkata\",\"Store-05\",\"Laptop\",\"2024-01-01\",72000),\n",
        "(\"T008\",\"East\",\"Kolkata\",\"Store-05\",\"Mobile\",\"2024-01-02\",28000),\n",
        "(\"T009\",\"East\",\"Patna\",\"Store-06\",\"Tablet\",\"2024-01-03\",23000),\n",
        "(\"T010\",\"West\",\"Mumbai\",\"Store-07\",\"Laptop\",\"2024-01-01\",80000),\n",
        "(\"T011\",\"West\",\"Mumbai\",\"Store-07\",\"Mobile\",\"2024-01-02\",35000),\n",
        "(\"T012\",\"West\",\"Pune\",\"Store-08\",\"Tablet\",\"2024-01-03\",27000),\n",
        "(\"T013\",\"North\",\"Delhi\",\"Store-01\",\"Laptop\",\"2024-01-04\",76000),\n",
        "(\"T014\",\"South\",\"Chennai\",\"Store-04\",\"Laptop\",\"2024-01-04\",79000),\n",
        "(\"T015\",\"East\",\"Patna\",\"Store-06\",\"Mobile\",\"2024-01-04\",29000),\n",
        "(\"T016\",\"West\",\"Pune\",\"Store-08\",\"Laptop\",\"2024-01-04\",77000),\n",
        "(\"T017\",\"North\",\"Chandigarh\",\"Store-02\",\"Mobile\",\"2024-01-05\",31000),\n",
        "(\"T018\",\"South\",\"Bangalore\",\"Store-03\",\"Mobile\",\"2024-01-05\",34000),\n",
        "(\"T019\",\"East\",\"Kolkata\",\"Store-05\",\"Tablet\",\"2024-01-05\",25000),\n",
        "(\"T020\",\"West\",\"Mumbai\",\"Store-07\",\"Tablet\",\"2024-01-05\",29000),\n",
        "(\"T021\",\"North\",\"Delhi\",\"Store-01\",\"Tablet\",\"2024-01-06\",28000),\n",
        "(\"T022\",\"South\",\"Chennai\",\"Store-04\",\"Tablet\",\"2024-01-06\",26000),\n",
        "(\"T023\",\"East\",\"Patna\",\"Store-06\",\"Laptop\",\"2024-01-06\",74000),\n",
        "(\"T024\",\"West\",\"Pune\",\"Store-08\",\"Mobile\",\"2024-01-06\",33000)\n",
        "]\n",
        "columns = [\n",
        "\"txn_id\",\"region\",\"city\",\"store_id\",\n",
        "\"product\",\"sale_date\",\"amount\"\n",
        "]\n",
        "df_sales = spark.createDataFrame(sales_data, columns)\n",
        "df_sales.show(5)\n",
        "df_sales.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exercise - 1\n",
        "1. Select only txn_id , region , product , and amount\n",
        "2. Rename amount to revenue\n",
        "3. Create a derived column amount_in_thousands\n",
        "4. Select distinct combinations of region and product\n",
        "5. Select all columns but exclude store_id\n",
        "6. Create a new column sale_year extracted from sale_date\n",
        "7. Reorder columns in a business-friendly format"
      ],
      "metadata": {
        "id": "KTk0B_nIqeJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_select = df_sales.select(\"txn_id\",\"region\",\"product\",\"amount\")\n",
        "df_select.show(5)\n"
      ],
      "metadata": {
        "id": "_MyDgvtiqxhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_renamed = df_sales.select(\n",
        "    \"txn_id\",\"region\",\"product\",\n",
        "    df_sales[\"amount\"].alias(\"revenue\")\n",
        ")\n",
        "df_renamed.show(5)\n"
      ],
      "metadata": {
        "id": "HssnbBFkrB5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import round, col\n",
        "df_amt_k = df_sales.withColumn(\n",
        "    \"amount_in_thousands\",\n",
        "    round(col(\"amount\") / 1000.0, 2)\n",
        ").select(\"txn_id\", \"region\", \"product\", \"amount\", \"amount_in_thousands\")\n",
        "df_amt_k.show(5)\n",
        "\n"
      ],
      "metadata": {
        "id": "ZMrs4ua_rPaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_distinct = df_sales.select(\"region\", \"product\").distinct()\n",
        "df_distinct.show()"
      ],
      "metadata": {
        "id": "Cis5_uehvjmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_no_store = df_sales.drop(\"store_id\")\n",
        "df_no_store.show(5, truncate=False)\n"
      ],
      "metadata": {
        "id": "0o7XNkkQwoFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import year, to_date\n",
        "df_with_year = (\n",
        "    df_sales\n",
        "    .withColumn(\"sale_date\", to_date(col(\"sale_date\")))  # cast to date\n",
        "    .withColumn(\"sale_year\", year(col(\"sale_date\")))\n",
        "    .select(\"txn_id\", \"region\", \"city\", \"store_id\", \"product\", \"sale_date\", \"sale_year\", \"amount\")\n",
        ")\n",
        "\n",
        "df_with_year.show(5, truncate=False)\n"
      ],
      "metadata": {
        "id": "d_rxajSvFXRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_with_year = (\n",
        "    df_sales\n",
        "    .withColumn(\"sale_date\", to_date(col(\"sale_date\")))  # cast to date\n",
        "    .withColumn(\"sale_year\", year(col(\"sale_date\")))\n",
        "    .select(\"txn_id\", \"region\", \"city\", \"store_id\", \"product\", \"sale_date\", \"sale_year\", \"amount\")\n",
        ")\n",
        "\n",
        "df_with_year.show(5, truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hksz2vc_F4xZ",
        "outputId": "c8f08add-6e5e-44d6-8c60-ae1bcedd4ed1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+----------+--------+-------+----------+---------+------+\n",
            "|txn_id|region|city      |store_id|product|sale_date |sale_year|amount|\n",
            "+------+------+----------+--------+-------+----------+---------+------+\n",
            "|T001  |North |Delhi     |Store-01|Laptop |2024-01-01|2024     |75000 |\n",
            "|T002  |North |Delhi     |Store-01|Mobile |2024-01-02|2024     |32000 |\n",
            "|T003  |North |Chandigarh|Store-02|Tablet |2024-01-03|2024     |26000 |\n",
            "|T004  |South |Bangalore |Store-03|Laptop |2024-01-01|2024     |78000 |\n",
            "|T005  |South |Chennai   |Store-04|Mobile |2024-01-02|2024     |30000 |\n",
            "+------+------+----------+--------+-------+----------+---------+------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EXERCISE SET 2 — FILTER OPERATIONS\n",
        "\n",
        "Objective\n",
        "Understand row-level filtering and predicate pushdown.\n",
        "Exercises\n",
        "1. Filter transactions where amount > 50000\n",
        "2. Filter only Laptop sales\n",
        "3. Filter sales from North and South regions\n",
        "4. Filter sales between 25000 and 75000\n",
        "5. Filter transactions from Delhi stores only\n",
        "6. Apply multiple filters using both filter and where\n",
        "7. Change the order of filters and compare explain(True)\n",
        "8. Identify which filters Spark pushes down"
      ],
      "metadata": {
        "id": "PWUxwSNqGkSO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_filter1 = df_sales.filter(df_sales[\"amount\"] > 50000)\n",
        "df_filter1.show(5)"
      ],
      "metadata": {
        "id": "aleCRHt6GmWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_filter2 = df_sales.filter(df_sales[\"product\"] == \"Laptop\")\n",
        "df_filter2.show()"
      ],
      "metadata": {
        "id": "nqHUFVpAGvIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_filter3 = df_sales.filter(\n",
        "    (df_sales[\"region\"] == \"North\") |\n",
        "    (df_sales[\"region\"] == \"South\")\n",
        ")\n",
        "df_filter3.show()\n"
      ],
      "metadata": {
        "id": "AlsEKV2SG7Jo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_filter4 = df_sales.filter(\n",
        "    (df_sales[\"amount\"] >= 25000) &\n",
        "    (df_sales[\"amount\"] <= 75000)\n",
        ")\n",
        "df_filter4.show()"
      ],
      "metadata": {
        "id": "PDkm7O0iHCCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_filter5 = df_sales.filter(df_sales[\"city\"] == \"Delhi\")\n",
        "df_filter5.show()"
      ],
      "metadata": {
        "id": "Wap5BxZyHHYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_multi_chain = (\n",
        "    df_sales\n",
        "    .filter(col(\"region\") == \"North\")\n",
        "    .where(col(\"product\") == \"Laptop\")\n",
        "    .filter(col(\"amount\") > 50000)\n",
        ")\n",
        "df_multi_chain.show(10, truncate=False)"
      ],
      "metadata": {
        "id": "MibVLjMKHLyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plan_a = (\n",
        "    df_sales\n",
        "    .filter(col(\"region\") == \"North\")\n",
        "    .filter(col(\"product\") == \"Laptop\")\n",
        "    .filter(col(\"amount\") > 50000)\n",
        ")\n",
        "plan_b = (\n",
        "    df_sales\n",
        "    .filter(col(\"amount\") > 50000)\n",
        "    .filter(col(\"product\") == \"Laptop\")\n",
        "    .filter(col(\"region\") == \"North\")\n",
        ")\n",
        "\n",
        "plan_a.explain(True)\n",
        "plan_b.explain(True)\n"
      ],
      "metadata": {
        "id": "T_2TIr9MHaS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EXERCISE SET 3 — GROUPBY & AGGREGATE\n",
        "FUNCTIONS\n",
        "\n",
        "Objective\n",
        "Perform summarization and understand shuffles.\n",
        "Exercises\n",
        "1. Total sales amount per region\n",
        "2. Average sales amount per product\n",
        "3. Maximum sale per city\n",
        "4. Minimum sale per store\n",
        "5. Count of transactions per region\n",
        "6. Total revenue per store\n",
        "7. Region-wise product sales count\n",
        "8. Average transaction value per city\n",
        "9. Identify regions with total sales above a threshold\n",
        "10. Use explain(True) and identify shuffle stages"
      ],
      "metadata": {
        "id": "5M7ICg_uH69B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, sum as _sum, avg, max as _max, min as _min, count\n",
        "total_sales_per_region = df_sales.groupBy(\"region\").agg(_sum(\"amount\").alias(\"total_amount\"))\n",
        "total_sales_per_region.orderBy(col(\"total_amount\").desc()).show(truncate=False)"
      ],
      "metadata": {
        "id": "6QuOd6zyIBNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_sales_per_product = df_sales.groupBy(\"product\").agg(avg(\"amount\").alias(\"avg_amount\"))\n",
        "avg_sales_per_product.orderBy(col(\"avg_amount\").desc()).show()"
      ],
      "metadata": {
        "id": "toSKawcBJTr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_sale_per_city = df_sales.groupBy(\"city\").agg(_max(\"amount\").alias(\"max_amount\"))\n",
        "max_sale_per_city.show()"
      ],
      "metadata": {
        "id": "PCD9gS9yJ7Vq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_sale_per_store = df_sales.groupBy(\"store_id\").agg(_min(\"amount\").alias(\"min_amount\"))\n",
        "min_sale_per_store.show()"
      ],
      "metadata": {
        "id": "Z1Hwct31Ksov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_transactions_per_region = df_sales.groupBy(\"region\").agg(count(\"*\").alias(\"transaction_count\"))\n",
        "count_transactions_per_region.show()"
      ],
      "metadata": {
        "id": "o1US1I5AK6YC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}